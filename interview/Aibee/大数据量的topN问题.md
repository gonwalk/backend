

## 1.常用的topN排序思路

海量数据处理 - 10亿个数中找出最大的10000个数（top K问题）：https://blog.csdn.net/zyq522376829/article/details/47686867

 前两天面试3面学长问我的这个问题（想说TEG的3个面试学长都是好和蔼，希望能完成最后一面，各方面原因造成我无比想去鹅场的心已经按捺不住了），这个问题还是建立最小堆比较好一些。

        先拿10000个数建堆，然后一次添加剩余元素，如果大于堆顶的数（10000中最小的），将这个数替换堆顶，并调整结构使之仍然是一个最小堆，这样，遍历完后，堆中的10000个数就是所需的最大的10000个。建堆时间复杂度是O（mlogm），算法的时间复杂度为O（nmlogm）（n为10亿，m为10000）。

        优化的方法：可以把所有10亿个数据分组存放，比如分别放在1000个文件中。这样处理就可以分别在每个文件的10^6个数据中找出最大的10000个数，合并到一起在再找出最终的结果。

        以上就是面试时简单提到的内容，下面整理一下这方面的问题：

top K问题
        在大规模数据处理中，经常会遇到的一类问题：在海量数据中找出出现频率最好的前k个数，或者从海量数据中找出最大的前k个数，这类问题通常被称为top K问题。例如，在搜索引擎中，统计搜索最热门的10个查询词；在歌曲库中统计下载最高的前10首歌等。
        针对top K类问题，通常比较好的方案是分治+Trie树/hash+小顶堆（就是上面提到的最小堆），即先将数据集按照Hash方法分解成多个小数据集，然后使用Trie树活着Hash统计每个小数据集中的query词频，之后用小顶堆求出每个数据集中出现频率最高的前K个数，最后在所有top K中求出最终的top K。

eg：有1亿个浮点数，如果找出期中最大的10000个？
        最容易想到的方法是将数据全部排序，然后在排序后的集合中进行查找，最快的排序算法的时间复杂度一般为O（nlogn），如快速排序。但是在32位的机器上，每个float类型占4个字节，1亿个浮点数就要占用400MB的存储空间，对于一些可用内存小于400M的计算机而言，很显然是不能一次将全部数据读入内存进行排序的。其实即使内存能够满足要求（我机器内存都是8GB），该方法也并不高效，因为题目的目的是寻找出最大的10000个数即可，而排序却是将所有的元素都排序了，做了很多的无用功。

        第二种方法为局部淘汰法，该方法与排序方法类似，用一个容器保存前10000个数，然后将剩余的所有数字——与容器内的最小数字相比，如果所有后续的元素都比容器内的10000个数还小，那么容器内这个10000个数就是最大10000个数。如果某一后续元素比容器内最小数字大，则删掉容器内最小元素，并将该元素插入容器，最后遍历完这1亿个数，得到的结果容器中保存的数即为最终结果了。此时的时间复杂度为O（n+m^2），其中m为容器的大小，即10000。

        第三种方法是分治法，将1亿个数据分成100份，每份100万个数据，找到每份数据中最大的10000个，最后在剩下的100*10000个数据里面找出最大的10000个。如果100万数据选择足够理想，那么可以过滤掉1亿数据里面99%的数据。100万个数据里面查找最大的10000个数据的方法如下：用快速排序的方法，将数据分为2堆，如果大的那堆个数N大于10000个，继续对大堆快速排序一次分成2堆，如果大的那堆个数N大于10000个，继续对大堆快速排序一次分成2堆，如果大堆个数N小于10000个，就在小的那堆里面快速排序一次，找第10000-n大的数字；递归以上过程，就可以找到第1w大的数。参考上面的找出第1w大数字，就可以类似的方法找到前10000大数字了。此种方法需要每次的内存空间为10^6*4=4MB，一共需要101次这样的比较。

        第四种方法是Hash法。如果这1亿个书里面有很多重复的数，先通过Hash法，把这1亿个数字去重复，这样如果重复率很高的话，会减少很大的内存用量，从而缩小运算空间，然后通过分治法或最小堆法查找最大的10000个数。

        第五种方法采用最小堆。首先读入前10000个数来创建大小为10000的最小堆，建堆的时间复杂度为O（mlogm）（m为数组的大小即为10000），然后遍历后续的数字，并于堆顶（最小）数字进行比较。如果比最小的数小，则继续读取后续数字；如果比堆顶数字大，则替换堆顶元素并重新调整堆为最小堆。整个过程直至1亿个数全部遍历完为止。然后按照中序遍历的方式输出当前堆中的所有10000个数字。该算法的时间复杂度为O（nmlogm），空间复杂度是10000（常数）。

实际运行：
        实际上，最优的解决方案应该是最符合实际设计需求的方案，在时间应用中，可能有足够大的内存，那么直接将数据扔到内存中一次性处理即可，也可能机器有多个核，这样可以采用多线程处理整个数据集。

       下面针对不容的应用场景，分析了适合相应应用场景的解决方案。

（1）单机+单核+足够大内存
        如果需要查找10亿个查询次（每个占8B）中出现频率最高的10个，考虑到每个查询词占8B，则10亿个查询次所需的内存大约是10^9 * 8B=8GB内存。如果有这么大内存，直接在内存中对查询次进行排序，顺序遍历找出10个出现频率最大的即可。这种方法简单快速，使用。然后，也可以先用HashMap求出每个词出现的频率，然后求出频率最大的10个词。

（2）单机+多核+足够大内存
        这时可以直接在内存总使用Hash方法将数据划分成n个partition，每个partition交给一个线程处理，线程的处理逻辑同（1）类似，最后一个线程将结果归并。

        该方法存在一个瓶颈会明显影响效率，即数据倾斜。每个线程的处理速度可能不同，快的线程需要等待慢的线程，最终的处理速度取决于慢的线程。而针对此问题，解决的方法是，将数据划分成c×n个partition（c>1），每个线程处理完当前partition后主动取下一个partition继续处理，知道所有数据处理完毕，最后由一个线程进行归并。

（3）单机+单核+受限内存
        这种情况下，需要将原数据文件切割成一个一个小文件，如次啊用hash(x)%M，将原文件中的数据切割成M小文件，如果小文件仍大于内存大小，继续采用Hash的方法对数据文件进行分割，知道每个小文件小于内存大小，这样每个文件可放到内存中处理。采用（1）的方法依次处理每个小文件。

（4）多机+受限内存
        这种情况，为了合理利用多台机器的资源，可将数据分发到多台机器上，每台机器采用（3）中的策略解决本地的数据。可采用hash+socket方法进行数据分发。



        从实际应用的角度考虑，（1）（2）（3）（4）方案并不可行，因为在大规模数据处理环境下，作业效率并不是首要考虑的问题，算法的扩展性和容错性才是首要考虑的。算法应该具有良好的扩展性，以便数据量进一步加大（随着业务的发展，数据量加大是必然的）时，在不修改算法框架的前提下，可达到近似的线性比；算法应该具有容错性，即当前某个文件处理失败后，能自动将其交给另外一个线程继续处理，而不是从头开始处理。

        top K问题很适合采用MapReduce框架解决，用户只需编写一个Map函数和两个Reduce 函数，然后提交到Hadoop（采用Mapchain和Reducechain）上即可解决该问题。具体而言，就是首先根据数据值或者把数据hash(MD5)后的值按照范围划分到不同的机器上，最好可以让数据划分后一次读入内存，这样不同的机器负责处理不同的数值范围，实际上就是Map。得到结果后，各个机器只需拿出各自出现次数最多的前N个数据，然后汇总，选出所有的数据中出现次数最多的前N个数据，这实际上就是Reduce过程。对于Map函数，采用Hash算法，将Hash值相同的数据交给同一个Reduce task；对于第一个Reduce函数，采用HashMap统计出每个词出现的频率，对于第二个Reduce 函数，统计所有Reduce task，输出数据中的top K即可。

        直接将数据均分到不同的机器上进行处理是无法得到正确的结果的。因为一个数据可能被均分到不同的机器上，而另一个则可能完全聚集到一个机器上，同时还可能存在具有相同数目的数据。



以下是一些经常被提及的该类问题。
（1）有10000000个记录，这些查询串的重复度比较高，如果除去重复后，不超过3000000个。一个查询串的重复度越高，说明查询它的用户越多，也就是越热门。请统计最热门的10个查询串，要求使用的内存不能超过1GB。

（2）有10个文件，每个文件1GB，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。按照query的频度排序。

（3）有一个1GB大小的文件，里面的每一行是一个词，词的大小不超过16个字节，内存限制大小是1MB。返回频数最高的100个词。

（4）提取某日访问网站次数最多的那个IP。

（5）10亿个整数找出重复次数最多的100个整数。

（6）搜索的输入信息是一个字符串，统计300万条输入信息中最热门的前10条，每次输入的一个字符串为不超过255B，内存使用只有1GB。

（7）有1000万个身份证号以及他们对应的数据，身份证号可能重复，找出出现次数最多的身份证号。



重复问题
        在海量数据中查找出重复出现的元素或者去除重复出现的元素也是常考的问题。针对此类问题，一般可以通过位图法实现。例如，已知某个文件内包含一些电话号码，每个号码为8位数字，统计不同号码的个数。

        本题最好的解决方法是通过使用位图法来实现。8位整数可以表示的最大十进制数值为99999999。如果每个数字对应于位图中一个bit位，那么存储8位整数大约需要99MB。因为1B=8bit，所以99Mbit折合成内存为99/8=12.375MB的内存，即可以只用12.375MB的内存表示所有的8位数电话号码的内容。

## 通过调整小顶堆取出topN

寻找TopN——在10亿数据中找到1000个最大的数：https://blog.csdn.net/yangljanfxp/article/details/83312596

问题描述
如何从10亿数据中找到前1000大的数？

解法
针对该问题，给定一个数组data，从中找出前n个最大的数。
解题思路
先维护一个具有n个数的堆，然后调整该堆为小顶堆，即每个父节点都比其子节点小。然后从剩下的数组中逐一读取数据，将读取到的数据跟堆顶比较。如果该数比堆顶小，直接丢弃；如果该数比堆顶数大，则用该数替换堆顶，重新调整该堆为小顶堆。等待所有数据处理完毕，这时候已经的小顶堆就是TopN。


public class TopN {
//	当前节点的父节点
	private int parent(int n){
		return (n-1)/2;
	}
//	当前节点的左子节点
	private int left(int n){
		return 2*n+1;
	}
//	当前节点的右子节点
	private int right(int n){
		return 2*n+2;
	}
//	构建堆
	private void buildHeap(int n, int[] data){
		for(int i=1;i<n;i++){
			int t=i;
			while(t!=0 && data[parent(t)]>data[t]){
				int temp = data[parent(t)];
				data[parent(t)]=data[t];
				data[t]=temp;
				t=parent(t);
			}
		}
	}
//	调整堆，为小顶堆
	private void adjust(int i, int n, int[] data){
		if(data[0]>=data[i]){
			return;
		}
		int temp = data[i];
	    data[i] = data[0];
	    data[0] = temp;
		int t=0;
//		调整时，堆顶比子节点大，从较小的子节点开始调整
		while((left(t)<n&&data[t]>data[left(t)])||(right(t)<n&&data[t]>data[right(t)])){
			if((right(t) < n && data[right(t)] < data[left(t)])){
				temp=data[t];
				data[t]=data[right(t)];
				data[right(t)]=temp;
				t=right(t);
			}else{
				temp=data[t];
				data[t]=data[left(t)];
				data[left(t)]=temp;
				t=left(t);
			}
		}
	}
//	寻找topN数
	public void findTopN(int n, int[] data){
		buildHeap(n,data);
		for(int i=n;i<data.length;i++){
			adjust(i,n,data);
		}
	}
//	打印
	public void print(int[] data){
		for(int i=0;i<data.length;i++){
			System.out.print(data[i]+",");
		}
	}
}


补充
这里寻找TopN的问题，也可以用分治法，类似快排。

随机选一个数t，对数组进行partition，这时数组一分为二，前一部分大于t，后一部分小于t。如果前一部分数据个数等于1000，直接结束；如果前一部分数据个数大于1000，那么在前一部分中继续partition；如果前一部分数据个数小于1000，那么在后一部分中partition。时间复杂度是o(n)，但10亿数据，占大量内存；改进：将数据写入文件中，但多次对磁盘读取，影响效率；再改进：采用分布式的思想。

在我看来，更好的是正文中介绍的方法，维护一个N个数的堆。


原文链接：https://blog.csdn.net/yangljanfxp/article/details/83312596


## 3.使用堆排序实现topN的过程

用堆处理大数据量的topN问题和排序问题：https://blog.csdn.net/KGLegolas/article/details/90721277


一般来说，涉及到topN类的问题时，我们首先想到的是采用分治法：先随机取一个数其他数与它比较，如果前一部分总数大于100个（这里架设找出前100条），那就继续在前一部分进行partition寻找；如果前一部分的数小于100个，那就在后一部分再进行partition。

然而当数据量大的时候，需要初始化加载全部数据，空间复杂度会特别大。或者将数据分步读入，分开进行partition再合并，但是这样操作又增加了磁盘的读写操作，效率受到影响。

这时候，我们可以考虑采用小顶堆的思想，在内存中维护一个100大小的小顶堆，然后每次读取一个数与堆顶进行比较，若比堆顶大，则把堆顶弹出，把当前数据压入堆顶，然后调整小顶堆，把数据从堆顶下移到一定位置即可，最终得到的小顶堆即为最大的100条数据。（我们可以将整个过程想象成一场挑战赛，战场中有100位英雄，剩下所有人依次挑战，每次选100人中的最弱的一个挑战，胜了则取代它，最终战场中留下的一定是最强的100个）

（相反如果要找最小前N个数可用大顶堆思想）同理可比作“每次选100人中的最强的一个挑战，输了则取代它，最终战场中留下的一定是最弱鸡的100个“

### 堆的概念
构建堆的基础是必须满足完全二叉树的结构，满足完全二叉树有两个条件：

从作为第一层的根开始，除了最后一层之外，第N层的元素个数都必须是2的N次方；第一层2个元素，第二层4个，第三层8个，以此类推。
而最后一行的元素，都要紧贴在左边，换句话说，每一行的元素都从最左边开始安放，两个元素之间不能有空闲。

具备了这两个特点的树，就是一棵完全二叉树 ，接下来再看堆的概念，堆分大根堆和小根堆：

大根堆：根结点的键值是所有堆结点键值中最大者（不仅大于其子节点，同时大于堆中的所有节点值）。每个节点的值都>=其左右孩子（如果有的话）值的完全二叉树。

小根堆：根结点的键值是所有堆结点键值中最小者（同理）。每个节点的值都<=其左右孩子值的完全二叉树。

我们用公式可以概括为：

大顶堆：arr[i] >= arr[2i+1] && arr[i] >= arr[2i+2]
小顶堆：arr[i] <= arr[2i+1] && arr[i] <= arr[2i+2]

如下图即为调整好的大根堆和小根堆：

![调整好的大顶堆和小顶堆](https://img-blog.csdnimg.cn/20190531183403493.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tHTGVnb2xhcw==,size_16,color_FFFFFF,t_70)

以下构建过程的内容参考自：https://www.cnblogs.com/chengxiao/p/6129630.html

### 堆的构建过程
下面我们通过图例讲解来认识将无序序列构造成一个大顶堆的过程：

1.假设给定无序序列结构如下：
![无序序列结构](https://img-blog.csdnimg.cn/20190531183434500.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tHTGVnb2xhcw==,size_16,color_FFFFFF,t_70)

2.我们构建堆时，从最后一个非叶结点开始（叶结点自然不用调整，第一个非叶子结点 arr.length/2-1=5/2-1=1，也就是下面的6结点），从左至右，从下至上进行调整。

![建堆调整过程1](https://img-blog.csdnimg.cn/20190531183445848.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tHTGVnb2xhcw==,size_16,color_FFFFFF,t_70)

完成6与子节点的调整之后，需要重新考量调整到的6位置的9作为根节点的那棵子树的两个子节点，是否还满足大根堆的原则（这里因为其是叶子节点，所以不加考虑，但是一定要时刻有这种思维）每一次交换，都必须要循环把子树部分判别清楚。

3.找到第二个非叶节点4，由于[4,9,8]中9元素最大，4和9交换

![建堆调整过程2](https://img-blog.csdnimg.cn/20190531183501904.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tHTGVnb2xhcw==,size_16,color_FFFFFF,t_70)


4,9交换之后，判断9的双子节点是否满足大根堆原则，这时发现子根[4,5,6]发生了结构混乱，所以继续调整

![建堆调整过程3](https://img-blog.csdnimg.cn/20190531183515261.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0tHTGVnb2xhcw==,size_16,color_FFFFFF,t_70)

此时，我们构造了一个大顶堆，至此我们将要筛选的数据依次与堆顶比较，若比堆顶小，则替换堆顶，然后重新调整大顶堆，如此循环最终堆里的元素就是所有数据里最小的N条。

### 堆的排序过程
我们对建好的堆的排序，其实就是如下的一个循环操作：

for (int j = heap.length - 1; j > 0; j–) {
1.堆首和堆尾的元素进行交换
2.对前j个元素的堆进行重排
}

小根堆的实现和排序
首先我们定义节点方法：

 // 父节点
    private int parent(int n) {
        return (n - 1) / 2;
    }

    // 左孩子
    private int left(int n) {
        return 2 * n + 1;
    }

    // 右孩子
    private int right(int n) {
        return 2 * n + 2;
    }

    void swap(int[] arr, int a, int b) {
        arr[a] = arr[a] ^ arr[b];
        arr[b] = arr[a] ^ arr[b];
        arr[a] = arr[a] ^ arr[b];
    }


然后我们给定一个无序数组构建一个小根堆：

private void buildMinHeap(int[] data) {
       //从根的第一个子节点开始遍历完整个数组
        for (int i = 1; i < data.length; i++) {
            int t = i;
            //从节点i不断向根节点遍历，若不满足最小堆条件则调整堆
            while (t != 0 && data[parent(t)] > data[t]) {
                swap(data, t, parent(t));
                t = parent(t);
            }
        }
    }


小根堆构建完成之后，开始对其进行排序操作：我们调整小根堆的时候每次从根节点开始，如果根节点大于子节点，则进行置换操作，且对于小根堆，我们置换左右节点中的更小的那一个，对于置换的子节点，被当作新的根节点进行新一轮的循环判断。（大根堆的调整逻辑与小根堆正好相反）

  public void sortMinHeap(int[] heap) {
        // 开始排序逻辑
        for (int j = heap.length - 1; j > 0; j--) {
            swap(heap, 0, j);//将堆顶元素与末尾元素进行交换
            int i = 0;
            //从根节点开始，如果根节点大于子节点，循环进行置换操作
            while ((left(i) < j && heap[i] > heap[left(i)])
                    || (right(i) < j && heap[i] > heap[right(i)])) {
                if (right(i) < j && heap[right(i)] < heap[left(i)]) {
                    // 右孩子更小，置换右孩子（总之与两者中更小的置换）
                    swap(heap, i, right(i));
                    i = right(i);
                } else {
                    // 否则置换左孩子
                    swap(heap, i, left(i));
                    i = left(i);
                }
            }
        }
    }

下面调用我们定义好的方法进行测试：

HeapSort heapSort = new HeapSort();
int[] arr1 = new int[]{56, 30, 71, 18, 29, 93, 44, 75, 20, 65}

heapSort.buildMinHeap(arr1);
System.out.println("构建的最小堆：");
System.out.println(Arrays.toString(arr1));

heapSort.sortMinHeap(arr1);
System.out.println("排序的最小堆：");
System.out.println(Arrays.toString(arr1));

测试输出如下：

构建的最小堆：
[18, 20, 44, 29, 30, 93, 71, 75, 56, 65]
排序的最小堆：
[93, 75, 71, 65, 56, 44, 30, 29, 20, 18]

利用小根堆解决TopN问题
上面，基于我们建好的小根堆，可以将需要筛选的元素依次与堆顶元素进行比较，若比堆顶大，则置换堆顶，然后对堆进行调整，最终，我们可以得到序列中前N条最大的记录。

我们定义adjustMinHeap方法temp为要与堆顶比较的元素，heap为我们建好的小根堆：

 private void adjustMinHeap(int temp, int[] heap) {
        int len = heap.length;
        if (temp <= heap[0]) {
            return;
        }
        //如果该数比堆顶大则置换堆顶
        heap[0] = temp;
        // 调整堆顶
        int i = 0;
        while ((left(i) < len && heap[i] > heap[left(i)])
                || (right(i) < len && heap[i] > heap[right(i)])) {
            if (right(i) < len && heap[right(i)] < heap[left(i)]) {
                // 右孩子更小，置换右孩子
                swap(heap, i, right(i));
                i = right(i);
            } else {
                // 否则置换左孩子
                swap(heap, i, left(i));
                i = left(i);
            }
        }
    }

然后定义findTopN方法，在该方法中对要筛选的数据进行循环比较。

 public void findTopN(int n, int[] heap, int[] data) {
        // n往后的数进行调整
        for (int i = n; i < data.length; i++) {
            adjustMinHeap(data[i], heap);
        }
    }

下面进行测试：

 HeapSort heapSort = new HeapSort();
    int[] arr1 = new int[]{56, 30, 71, 18, 29, 93, 44, 75, 20, 65, 68, 34, 30, 23, 45, 67, 84, 234, 676, 43, 75, 35, 675, 75, 33};
    int heapLen = 10;
    //我们先取前10个元素构建一个最小堆
    int[] heap = Arrays.copyOf(arr1, heapLen);
    heapSort.buildMinHeap(heap);
    System.out.println("构建的最小堆：");
    System.out.println(Arrays.toString(heap));

    //然后调用findTopN方法去循环遍历调整堆
    heapSort.findTopN(heapLen, heap, arr1);
    System.out.println("调整后数组：");
    System.out.println(Arrays.toString(heap));


测试输出如下：

构建的最小堆：
[18, 20, 44, 29, 30, 93, 71, 75, 56, 65]
调整后数组：
[68, 75, 71, 75, 75, 93, 84, 675, 234, 676]

大根堆的实现和排序与小根堆同理，大同小异。

### 堆排序的复杂度
初始化建堆的时间复杂度为O(n)，排序重建堆的时间复杂度为nlog(n)，所以总的时间复杂度为O(n+nlogn)=O(nlogn) ，因为堆排序是就地排序，所以空间复杂度为O（1）