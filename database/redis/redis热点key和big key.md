# 1.redis的热key问题与解决方案
参考：
【原创】谈谈redis的热key问题如何解决：https://www.cnblogs.com/rjzheng/p/10874537.html

## 1.1 引言

何为热key问题？就是瞬间有大量（比如几十万）的请求去访问redis上某个固定的key，这样会造成流量过于集中，达到物理网卡上限，从而压垮缓存服务的情况。大量的对这个key的请求，会直接去数据库上去查询，导致DB击穿，影响服务的可用性。

其实生活中也是有不少这样的例子。例如微博上热点事件，比如说XX明星突然公布结婚。那么关于XX明星的Key就会瞬间增大，就会出现热数据问题。

ps:hot key和big key问题，一定要有所了解，面试及实际工作中会用到。

### 1.1.1 热点Key问题产生的原因 

Redis热点Key发现及常见解决方案：https://www.cnblogs.com/dz11/p/10315184.html

1、用户消费的数据远大于生产的数据（热卖商品、热点新闻、热点评论、明星直播）。

在日常工作生活中一些突发的的事件，例如：双十一期间某些热门商品的降价促销，当这其中的某一件商品被数万次点击浏览或者购买时，会形成一个较大的需求量，这种情况下就会造成热点问题。

同理，被大量刊发、浏览的热点新闻、热点评论、明星直播等，这些典型的读多写少的场景也会产生热点问题。

2、请求分片集中，超过单 Server 的性能极限。

在服务端读数据进行访问时，往往会对数据进行分片切分，此过程中会在某一主机 Server 上对相应的 Key 进行访问，当访问超过 Server 极限时，就会导致热点 Key 问题的产生。

### 1.1.2 热点Key问题的危害

1、流量集中，达到物理网卡上限。

当某一热点 Key 的请求在某一主机上超过该主机网卡上限时，由于流量的过度集中，可能导致服务器中其它服务无法进行。 

2、请求过多，缓存分片服务被打垮。

如果热点过于集中，热点 Key 的缓存过多，超过目前的缓存容量时，就会导致缓存分片服务被打垮这种现象的产生。

3、DB 击穿，引起业务雪崩。

![DB被击穿](https://user-gold-cdn.xitu.io/2019/1/24/1687ef0323ad3231?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

当缓存服务崩溃后，此时再有请求产生，会缓存到后台 DB 上，由于DB 本身性能较弱，在面临大请求时很容易发生请求穿透现象，会进一步导致雪崩，严重影响设备的性能。


## 1.2 如何发现热key

方法一:凭借业务经验，进行预估哪些是热key

其实这个方法还是挺有可行性的。比如某商品在做秒杀，那么用这个商品的key就可以判断出是不是热key。缺点很明显，并非所有业务都能预估出哪些key是热key。

方法二:在客户端进行收集

这个方式就是在操作redis之前，加入一行代码进行数据统计。这个数据统计的方式有很多种，可以用redis命令，也可以是给外部的通讯系统发送一个通知信息，比如Kafka、RocketMQ等消息队列系统。缺点就是对客户端代码造成入侵。

方法三:在Proxy层做收集

有些集群架构是下面这样的，Proxy可以是Twemproxy，是统一的入口。可以在Proxy层做收集上报，但是缺点很明显，并非所有的redis集群架构都有proxy。

方法四:用redis自带命令

(1)monitor命令，该命令可以实时抓取出redis服务器接收到的命令，然后写代码统计出热key是哪些。当然，也有现成的分析工具可以使用，比如redis-faina。但是该命令在高并发的条件下，有内存暴增的隐患，还会降低redis的性能。

(2)hotkeys参数，redis 4.0.3在redis客户端redis-cli提供有热点key发现功能，执行redis-cli时加上 –hotkeys 选项即可。但是该参数在执行的时候，如果key比较多，执行起来比较慢。

Redis 4.0热点Key查询方法：https://help.aliyun.com/knowledge_detail/101108.html

方法五:自己抓包评估

Redis客户端使用TCP协议与服务端进行交互，通信协议采用的是RESP。自己写程序监听端口，按照RESP协议规则解析数据，进行分析。缺点就是开发成本高，维护困难，有丢包可能性。

以上五种方案，各有优缺点。根据自己业务场景进行抉择即可。那么发现热key后，如何解决呢？

## 1.3 如何解决


1、服务端缓存方案

 首先 Client 会将请求发送至 Server 上，而 Server 又是一个多线程的服务，本地就具有一个基于 Cache LRU 策略的缓存空间。
 

当 Server 本身就拥堵时，Server 不会将请求进一步发送给 DB 而是直接返回，只有当 Server 本身畅通时才会将 Client 请求发送至 DB，并且将该数据重新写入到缓存中。

此时就完成了缓存的访问跟重建。

但该方案也存在以下问题：

缓存失效，多线程构建缓存问题

缓存丢失，缓存构建问题

脏读问题

2、使用 Memcache、Redis 方案

 该方案通过在客户端单独部署缓存的方式来解决热点 Key 问题。
 

使用过程中 Client 首先访问服务层，再对同一主机上的缓存层进行访问。

该种解决方案具有就近访问、速度快、没有带宽限制的优点，但是同时也存在以下问题：

内存资源浪费

脏读问题

3、使用本地缓存方案

使用本地缓存则存在以下问题：

需要提前获知热点

缓存容量有限

不一致性时间增长

热点 Key 遗漏

传统的热点解决方案都存在各种各样的问题，那么究竟该如何解决热点问题呢？

4、读写分离方案解决热读

 架构中各节点的作用如下：
 

SLB 层做负载均衡

Proxy 层做读写分离自动路由

Master 负责写请求

ReadOnly 节点负责读请求

Slave 节点和 Master 节点做高可用

实际过程中 Client 将请求传到 SLB，SLB 又将其分发至多个 Proxy 内，通过 Proxy 对请求的识别，将其进行分类发送。

例如，将同为 Write 的请求发送到 Master 模块内，而将 Read 的请求发送至 ReadOnly 模块。

而模块中的只读节点可以进一步扩充，从而有效解决热点读的问题。

读写分离同时具有可以灵活扩容读热点能力、可以存储大量热点Key、对客户端友好等优点。

5、热点数据解决方案

 该方案通过主动发现热点并对其进行存储来解决热点 Key 的问题。
 

首先 Client 也会访问 SLB，并且通过 SLB 将各种请求分发至 Proxy 中，Proxy 会按照基于路由的方式将请求转发至后端的 Redis 中。

在热点 key 的解决上是采用在服务端增加缓存的方式进行。

具体来说就是在 Proxy 上增加本地缓存，本地缓存采用 LRU 算法来缓存热点数据，后端 db 节点增加热点数据计算模块来返回热点数据。

Proxy 架构的主要有以下优点：

Proxy 本地缓存热点，读能力可水平扩展

DB 节点定时计算热点数据集合

DB 反馈 Proxy 热点数据

对客户端完全透明，不需做任何兼容

四、热点 key 处理 1、热点数据的读取

 在热点 Key 的处理上主要分为写入跟读取两种形式，在数据写入过程当 SLB 收到数据 K1 并将其通过某一个 Proxy 写入一个 Redis，完成数据的写入。
 

假若经过后端热点模块计算发现 K1 成为热点 key 后， Proxy 会将该热点进行缓存，当下次客户端再进行访问 K1 时，可以不经 Redis。

最后由于 proxy 是可以水平扩充的，因此可以任意增强热点数据的访问能力。

2、热点数据的发现

 对于 db 上热点数据的发现，首先会在一个周期内对 Key 进行请求统计，在达到请求量级后会对热点 Key 进行热点定位，并将所有的热点 Key 放入一个小的 LRU 链表内，在通过 Proxy 请求进行访问时，若 Redis 发现待访点是一个热点，就会进入一个反馈阶段，同时对该数据进行标记。
 

DB 计算热点时，主要运用的方法和优势有：

1、基于统计阀值的热点统计

2、基于统计周期的热点统计

3、基于版本号实现的无需重置初值统计方法

4、DB 计算同时具有对性能影响极其微小、内存占用极其微小等优点

五、方案对比 通过上述对比分析可以看出，在解决热点 Key 上较传统方法相比都有较大的提高，无论是基于读写分离方案还是热点数据解决方案，在实际处理环境中都可以做灵活的水平能力扩充、都对客户端透明、都有一定的数据不一致性。

此外读写分离模式可以存储更大量的热点数据，而基于 Proxy 的模式有成本上的优势。




目前业内使用的方案主要有两种：
(1)利用二级缓存
比如利用ehcache，或者一个HashMap都可以。当发现热key以后，把热key加载到系统的本地JVM中。

针对这种热key请求，会直接从JVM中取，而不会走到redis层。
假设此时有十万个针对同一个key的请求过来，如果没有本地缓存，这十万个请求就直接怼到同一台redis上了。

现在假设，应用层有50台机器，同时也有jvm缓存。这十万个请求平均分散开来，每个机器有2000个请求，会从JVM中取到value值，然后返回数据。避免了十万个请求怼到同一台redis上的情形。

(2)备份热key

这个方案的思路是，不要让key走到同一台redis上。可以将这些热key，在多个redis上都存一份。当有热key请求进来的时候，就在有备份的redis上随机选取一台，进行访问取值，返回数据。
假设redis的集群数量为N，步骤如下图所示

![从redis集群中随机选取一个座位热key的访问机器](https://img2018.cnblogs.com/blog/725429/201905/725429-20190516112222759-656135438.png)

注:不一定是2N，取3N，4N都可以，看要求。
伪代码如下

const M = N * 2
//生成随机数
random = GenRandom(0, M)
//构造备份新key
bakHotKey = hotKey + "_" + random
data = redis.GET(bakHotKey)
if data == NULL {
    data = GetFromDB()
    redis.SET(bakHotKey, expireTime + GenRandom(0,5))
}

(3)程序自动发现热key并处理

有没有办法在项目运行过程中，自动发现热key，然后程序自动处理么？

常用来自动发现热key的过程，可以分为两步：
1)监控热key
2)通知系统做处理

有赞出了一篇《有赞透明多级缓存解决方案（TMC）》，里头也有提到热点key问题，在这里借此加以说明。

1)监控热key
在监控热key方面，有赞用的是方式二：在客户端进行收集。
在《有赞透明多级缓存解决方案（TMC）》中有一句话提到：
```
TMC 对原生jedis包的JedisPool和Jedis类做了改造，在JedisPool初始化过程中集成TMC“热点发现”+“本地缓存”功能Hermes-SDK包的初始化逻辑。
```

也就说人家改写了jedis原生的jar包，加入了Hermes-SDK包。
那Hermes-SDK包用来干嘛？
其实，就是做热点发现和本地缓存。

从监控的角度看，该包对于Jedis-Client的每次key值访问请求，Hermes-SDK 都会通过其通信模块将key访问事件异步上报给Hermes服务端集群，以便其根据上报数据进行“热点探测”。

当然，这只是其中一种方式，有的公司在监控方面用的是方式五:自己抓包评估。
具体是这么做的，先利用flink搭建一套流式计算系统。然后自己写一个抓包程序抓redis监听端口的数据，抓到数据后往kafka里丢。
接下来，流式计算系统消费kafka里的数据，进行数据统计即可，也能达到监控热key的目的。

(2)通知系统做处理
在这个角度，有赞用的是上面的解决方案一:利用二级缓存进行处理。
有赞在监控到热key后，Hermes服务端集群会通过各种手段通知各业务系统里的Hermes-SDK，告诉他们:"这个key是热key，记得做本地缓存。"

于是Hermes-SDK就会将该key缓存在本地，对于后面的请求。Hermes-SDK发现这个是一个热key，直接从本地中拿，而不会去访问集群。

除了这种通知方式以外，也可以这么做，比如使用流式计算系统监控到热key，往zookeeper里头的某个节点里写。然后业务系统监听该节点，发现节点数据变化了，就代表发现热key。最后往本地缓存里写，也是可以的。

通知方式各种各样，大家可以自由发挥。本文只是提供一个思路。



# 2.redis中的大key问题

redis bigkey 解决 删除大key：
https://blog.csdn.net/u010522235/article/details/89241765


大Key会带来的问题

如果是集群模式下，无法做到负载均衡，导致请求倾斜到某个实例上，而这个实例的QPS会比较大，内存占用也较多；对于Redis单线程模型又容易出现CPU瓶颈，当内存出现瓶颈时，只能进行纵向库容，使用更牛逼的服务器。
涉及到大key的操作，尤其是使用hgetall、lrange 0 -1、get、hmget 等操作时，网卡可能会成为瓶颈，也会到导致堵塞其它操作，qps 就有可能出现突降或者突升的情况，趋势上看起来十分不平滑，严重时会导致应用程序连不上，实例或者集群在某些时间段内不可用的状态。
假如这个key需要进行删除操作，如果直接进行DEL 操作，被操作的实例会被Block住，导致无法响应应用的请求，而这个Block的时间会随着key的变大而变长。
排查大key方法

在redis实例上执行bgsave，然后我们对dump出来的rdb文件进行分析，找到其中的大KEY
有个不太推荐的命令，debug object xxx 可以看到这个key在内存中序列化后的大小，当然我们可以通过SCAN+debug object xxx 得到当前实例所有key的大小。
redis-cli 原生自带 –bigkeys 功能，可以找到某个实例 5种数据类型(String、hash、list、set、zset)的最大key。
————————————————
版权声明：本文为CSDN博主「发歌的数据架构」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/u010522235/article/details/89241765


redis的--bigkeys参数：对redis整个keyspace进行统计（数据量大时采样，调用scan命令），寻找每种数据类型较大的keys，给出数据统计
redis-cli --bigkeys -i 0.1 -h 127.0.0.1

查看原文：http://www.architecy.com/archives/238



Redis 单key值过大 优化方式：https://blog.csdn.net/beyond59241/article/details/84848435

Redis使用过程中经常会有各种大key的情况， 比如：

1： 单个简单的key存储的value很大
2： hash， set，zset，list 中存储过多的元素（以万为单位）
由于redis是单线程运行的，如果一次操作的value很大会对整个redis的响应时间造成负面影响，所以，业务上能拆则拆，下面举几个典型的分拆方案。

1、单个简单的key存储的value很大
1.1、 改对象需要每次都整存整取
可以尝试将对象分拆成几个key-value， 使用multiGet获取值，这样分拆的意义在于分拆单次操作的压力，将操作压力平摊到多个redis实例中，降低对单个redis的IO影响；

1.2、该对象每次只需要存取部分数据
可以像第一种做法一样，分拆成几个key-value， 也可以将这个存储在一个hash中，每个field代表一个具体的属性，使用hget,hmget来获取部分的value，使用hset，hmset来更新部分属性

2、 hash， set，zset，list 中存储过多的元素
类似于场景一种的第一个做法，可以将这些元素分拆。

以hash为例，原先的正常存取流程是 hget(hashKey, field) ; hset(hashKey, field, value)
现在，固定一个桶的数量，比如 10000， 每次存取的时候，先在本地计算field的hash值，模除 10000， 确定了该field落在哪个key上。

newHashKey  =  hashKey + (*hash*(field) % 10000）;   
hset (newHashKey, field, value) ;  
hget(newHashKey, field)
set, zset, list 也可以类似上述做法.

但有些不适合的场景，比如，要保证 lpop 的数据的确是最早push到list中去的，这个就需要一些附加的属性，或者是在 key的拼接上做一些工作（比如list按照时间来分拆）。

redis一个实例能存多少key，key与value最大是多少？
https://blog.csdn.net/u011383596/article/details/80728241

官方说单例能处理key：2.5亿个，参考链接:https://redis.io/topics/faq

redis可以处理2^32 = 2.5亿个key，每个hash、list、set、sorted set可以存放2^32个元素。换句话说，redis存放key的最大值很可能受限于系统的内存。

redis中，每个key的最大值是512MB，每个value的最大值的上限为512MB。
