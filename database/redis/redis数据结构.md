# 1.基本数据结构

字符串string、列表list、集合set、有序集合sorted set、哈希hash。


# 2.哈希



## 2.1 哈希
Redis Hash：https://www.jianshu.com/p/28d4198085c8

什么是哈希
哈希hash又称为散列、杂凑等，是将任意长度的输入通过散列算法变换为固定长度的输出，最终输出也就是哈希值。这种转换是一种压缩映射。也就是说，散列值的空间通常要远小于输入控件，不同的输入可能会散列成相同的输出，所以不可能通过散列值来确定唯一的输入值。

哈希
什么是哈希表
哈希表hash table是为了将数据映射到数组中某个位置，通过数组下标访问元素以提高数据的查询速度，这种查询的平均期望时间复杂度为O(1)。

例如：有4个整数分别为6、7、9、12，需要映射到数组中。

方案1：新开一个长度为13的数组，将对应值放置到对应的下标。

下标对应
问题是这样做，会浪费没有被映射到的位置的空间。

方案2：采用哈希表的做法，申请长度为4的数组，将每个数的值对数组长度4取模，然后放置到对应的数组槽位中，这样就把离散的数据映射到了连续的空间，所以哈希表又称为散列表。

哈希表
采用哈希表的好处是最大限度地提升空间的利用率，而且查询效率还很高。不过问题来了，如果这4个数是6、7、8、11呢？由于7和11对4取模的值都是3，所以它们会占据同一个槽位。

散列冲突
这种情况我们称为冲突(collision)，解决冲突的方式有开放地址法、再散列法、链地址法等。Redis采用的是链地址法，简单来说，链地址法就是将有冲突的数据用一个链表给串联起来。

链地址法
使用链地址法，就算有冲突也可以将有冲突的数据存储在一起。只是存储结构需要稍加变化，哈希表的每个元素将变成一个指针，指向数据链表的链表头，每次有新数据来时从链表头插入，可以达到插入的时间复杂度保持在O(1)。

Redis中的字典
在Redis中，hash哈希被称为字典（dictionary），Redis的字典使用哈希表作为底层实现，一个哈希表里面可以有多个哈希表节点，而每个哈希表节点保存了字典中的一个键值对。实际上，Redis数据库底层也是采用哈希表来存储键值对的。

Redis中的字典
Redis中的哈希采用了典型的挂链解决冲突的方式，当有多个key-value键值对的键名key映射值相同时，系统会将这些键值value以单链表的形式保存，同时为了控制哈希表占用内存大小，Redis采用了双哈希表ht[2]结构，并逐步扩大哈希表容量的策略。注意，每对key-value在保存前会通过类似HASH(key) MOD N的方法计算出一个值，以确定在哈希表中所对应的位置。

Redis hash数据结构
Redis中一个哈希存储一条数据，一个字段field则存储一条数据中的一个属性，字段值value是属性对应的值。每个哈希hash可存储2^32-1个键值对，约40多亿个。Redis中的哈希散列类型与Java中的HashMap相似，都是一组键值对的集合，并且支持单独对其中一个键进行增删改查操作。

哈希键值对
为什么哈希更适合存储对象呢？
哈希存储对象
Redis中的哈希散列适用于存储对象，将一个对象存储在哈希类型中会占用更小的内存。将对象的每个字段存储为单个的string字符串类型，进而将一个对象存储在hash类型中，这样会占用更少的内存并能更方便的存储整个对象。

哈希存储对象
为什么使用哈希会更加节省内存呢？
Redis中的哈希散列是一个string类型的field和value的映射表，它的增删操作的复杂度平均为O(1)。为什么平均是O(1)呢？因为哈希的内部结构包含zipmap和hash两种。hash适合存储对象，相对于对象序列化存储为string字符串类型，将对象存储在hash哈希类型中会占用更少的内存。zipmap本身并不是hashtable，由于zip压缩后可以节省hash本身所需的元数据的开销。因此zipmap的增删改查的操作复杂度为O(n)。但是域字段field的数量不多，所以说平均是O(1)。那么，为什么会占用更好的内存呢？因为对象刚开始使用的是zipmap存储的。

在新建一个哈希的时候，使用的是zipmap又称为small hash存储的。这个zipmap实际上不是我们的哈希表。但是这个zipmap相比正常的哈希实现，节省很多哈希自身所需要的元数据的存储开销。尽管zipmap的增删改查和字段的数目相关，字段太多速度会更慢。因此不建议设置过多的字段。在Redis内部，如果字段过多或者存储的值太大超过限制后，Redis会自动将zipmap替换为正常的hash来实现。

在域字段field的数量在限制范围内，并且字段值value的长度大小系统限定的字节数，此时哈希类型是用zipmap存储的，所以会比较节省内存空间。

# 配置域字段最大个数限制
hash-max-zipmap-entries 512

# 配置字段值最大字节限制
hash-max-zipmap-value 64
当满足以上两个条件法时，哈希表key会被压缩，否则将按照正常的哈希结构来存储。

Redis中哈希与集合的异同点
哈希与集合
set以普通的key-value键值对的方式存储，可以设置过期时间，时间复杂度为O(1)，每执行一个set就会在Redis中多出一个key。

hset是以哈希散列表的形式存储，超时时间只能设置在键key上，单个域field不能设置过期时间。时间复杂度为O(n)，n是单个哈希上的field域个数。所以，单个哈希并不适合存储大量的字段field，过多的字段field会比较消耗CPU。但优点在于散列表存储会比较节省内存。

实际应用中，应该使用set集合存储单个大文本的非结构化数据，使用hset哈希散列表来存储结构化数据。

Redis中对哈希的操作
Redis中对hash类型的操作
hset key field value

将哈希表key中的字段field的值设置为value，若key不存在则创建后赋值，若域field已存在则覆盖。
Redis中hset命令用于为哈希表中的字段赋值，如果哈希表不存在则创建并进行字段赋值，否则原字段值将被新字段值所覆盖。
若字段是哈希表中新建的字段且字段值设置成功则返回1，若哈希表中域字段已经存在且 旧值被新值覆盖成功则返回0。
$ redis-cli
127.0.0.1:6379> hset username "junchow"
(error) ERR wrong number of arguments for 'hset' command

# 错误：set或map的size为0，一个没有值的set或map。





## 哈希冲突与解决

redis字典 - 哈希算法，解决键冲突， rehash , 渐进式rehash,字典API
http://www.manongjc.com/article/17720.html


# 使用redis实现消息队列的几种方式

Redis实现消息队列的4种方案：https://www.jianshu.com/p/d32b16f12f09


redis作为一种内存KV数据库，提供了string, hash, list, set, zset等多种数据结构。


Redis作为内存中的数据结构存储，常用作数据库、缓存和消息代理。它支持的数据结构有：字符串，列表，散列（哈希），集合，带有范围查询的排序集（sorted sets），位图（bitmaps），超级日志（hyperloglogs），具有半径查询和流的地理空间索引。

Redis具有内置复制，Lua脚本，LRU驱逐，事务和不同级别的磁盘持久性，并通过Redis Sentinel和Redis Cluster自动分区。

为了实现其出色的性能，Redis使用内存数据集（in-memory dataset）。

消息队列MQ应用（框架）有很多，比如ActiveMQ、RabbitMQ、Kafka等。除此之外，也可以基于redis来实现，这样可以降低系统的维护成本和实现复杂度，这里介绍使用redis实现消息队列的几种方案。
```
1. 基于List的 LPUSH+BRPOP 的实现

2. PUB/SUB，订阅/发布模式

3. 基于Sorted-Set的实现

4. 基于Stream类型的实现
```

## 1.基于异步消息队列List lpush-brpop(rpush-blpop)

使用rpush和lpush操作入队列，lpop和rpop操作出队列。

List支持多个生产者和消费者并发进出消息，每个消费者拿到都是不同的列表元素。

但是当队列为空时，lpop和rpop会一直空轮训，消耗资源；所以引入阻塞读blpop和brpop（b代表blocking），阻塞读在队列没有数据的时候进入休眠状态，

一旦数据到来则立刻醒过来，消息延迟几乎为零。

注意:

对于上面的方案，还有个问题需要解决：空闲连接的问题。

如果线程一直阻塞在那里，Redis客户端的连接就成了闲置连接，闲置过久，服务器一般会主动断开连接，减少闲置资源占用，这个时候blpop和brpop或抛出异常，

所以在编写客户端消费者的时候要小心，如果捕获到异常，还有重试。

缺点：

做消费者确认ACK麻烦，不能保证消费者消费消息后是否成功处理的问题（宕机或处理异常等），通常需要维护一个Pending列表，保证消息处理确认。

不能做广播模式，如pub/sub，消息发布/订阅模型；

不能重复消费，一旦消费就会被删除；

不支持分组消费；

## 2.SUB/PUB 订阅/发布模式 

此模式允许生产者只生产一次消息，由中间件负责将消息复制到多个消息队列，每个消息队列由对应的消费组消费。

```
SUBSCRIBE，用于订阅信道

PUBLISH，向信道发送消息

UNSUBSCRIBE，取消订阅
```

### 优点

典型的广播模式，一个消息可以发布到多个消费者。

多信道订阅，消费者可以同时订阅多个信道，从而接收多类消息。

消息即时发送，消息不用等待消费者读取，消费者会自动接收到信道发布的消息。

### 缺点
```
由于是广播模式，消息一旦发布，不能及时接收则丢失。换句话就是发布时若客户端不在线，则消息丢失，不能寻回。

不能保证每个消费者接收的时间是一致的。

若消费者客户端出现消息积压，到一定程度，会被强制断开，导致消息意外丢失，这种情况通常发生在消息的生产远大于消费速度时。
```
可见，Pub/Sub 模式不适合做消息存储或消息积压类的业务，而是擅长处理广播，即时通讯，即时反馈的业务。

## 3.基于Sorted-Set的实现

有序集合zset在增删改查的性质上类似于C++ stl的map和Java的TreeMap，提供了一组“键-值”对，并且“键”按照“值”的顺序排序。但是与C++ stl或Java的红黑树实现不同的是，redis中有序集合的实现采用了另一种数据结构————跳跃表。跳跃表是有序单链表的一种改进，其查询、插入、删除也是O(logN)的时间复杂度。

Sorted Set(有序集合)，类似于java的SortedSet和HashMap的结合体，一方面它是一个集合set，保证内部value的唯一性；另一方面它可以给每个value赋予一个score，代表这个value的排序权重。sorted set的内部实现是“跳跃表”。

redis选择跳跃表而非红黑树作为有序集合实现方式的原因并非是基于并发上的考虑，因为redis是单线程的，选用跳跃表是因为跳跃表的实现相较于红黑树更加简洁。

### 基于有序集合sorted set实现消息队列

利用Sorted Set依据score排序的特征，可以实现一个有序的消息队列。
有序集合的方案是在自己确定消息顺序时比较常用，（有序集合底层使用“跳跃表”实现，跳表有key、value、score等属性）使用集合成员的score来作为消息ID，保证顺序。可以采用时间戳+序号的方案，这样可以确保消息ID的单调递增。

### 优点

就是可以自定义消息ID，在消息ID有意义时，比较重要。

### 缺点

缺点也明显，不允许重复消息（因为是集合），同时消息ID确定有错误会导致消息的顺序出错。

## 4.基于Stream类型的实现

Stream为redis 5.0后新增的数据结构。支持多播的可持久化消息队列，实现借鉴了Kafka设计。

Redis Stream结构中，有一个消息链表，将所有加入的消息都串起来，每个消息都有一个唯一的ID和对应的内容。消息是持久化的，Redis重启后，内容还在。

每个Stream都有唯一的名称，它就是Redis的key，在首次使用xadd指令追加消息时自动创建。

每个Stream都可以挂多个消费组，每个消费组会有个游标last_delivered_id在Stream数组之上往前移动，表示当前消费组已经消费到哪条消息了。每个消费组在Stream内都有一个唯一的名称，消费组不会自动创建，它需要单独的指令xgroup create进行创建，需要指定从Stream的某个消息ID开始消费，这个ID用来初始化last_delivered_id变量。

每个消费组(Consumer Group)的状态都是独立的，相互不受影响。也就是说同一份Stream内部的消息会被每个消费组都消费到。

同一个消费组(Consumer Group)可以挂接多个消费者(Consumer)，这些消费者之间是竞争关系，任意一个消费者读取了消息都会使游标last_delivered_id往前移动。每个消费者者有一个组内唯一名称。

消费者(Consumer)内部会有个状态变量pending_ids，它记录了当前已经被客户端读取的消息，但是还没有ack。如果客户端没有ack，这个变量里面的消息ID会越来越多，一旦某个消息被ack，它就开始减少。这个pending_ids变量在Redis官方被称之为PEL，也就是Pending Entries List，这是一个很核心的数据结构，它用来确保客户端至少消费了消息一次，而不会在网络传输的中途丢失没处理。

### 增删改查

```
xadd 追加消息

xdel 删除消息，这里的删除仅仅是设置了标志位，不影响消息总长度

xrange 获取消息列表，会自动过滤已经删除的消息

xlen 消息长度

del 删除Stream
```

### 独立消费

可以在不定义消费组的情况下进行Stream消息的独立消费，当Stream没有新消息时，甚至可以阻塞等待。Redis设计了一个单独的消费指令xread，可以将Stream当成普通的消息队列(list)来使用。使用xread时，可以完全忽略消费组(Consumer Group)的存在，就好比Stream就是一个普通的列表(list)。

### 创建消费组

Stream通过xgroup create指令创建消费组(Consumer Group)，需要传递起始消息的ID作为参数，用来初始化last_delivered_id变量。

### 消费

Stream提供了xreadgroup指令，进行消费组内的消息消费，该指令需要提供消费组名称、消费者名称和起始消息ID。它同xread一样，也可以阻塞等待新消息。读到新消息后，对应的消息ID就会进入消费者的PEL(正在处理的消息)结构里，客户端处理完毕后使用xack指令通知服务器，本条消息已经处理完毕，该消息ID就会从PEL中移除。

### Stream消息太多怎么办

要是消息积累太多，Stream的链表岂不是很长，内容会不会爆掉。xdel指令又不会删除消息，它只是给消息做了个标志位。

Redis考虑到了这一点，所以它提供了一个定长Stream功能。在xadd的指令提供一个定长长度maxlen，就可以将老的消息清除，确保最多不超过指定长度。
```
127.0.0.1:6379> xlen codehole

(integer) 5

127.0.0.1:6379> xadd codehole maxlen 3 * name xiaorui age 1

1527855160273-0

127.0.0.1:6379> xlen codehole

(integer) 3
```
可以看到Stream的长度被砍掉了。

### 消息如果忘记ACK会怎样

Stream在每个消费者结构中保存了正在处理中的消息ID列表PEL，如果消费者发现消息处理完但是没有回复ack，就会导致PEL列表不断增长；如果有很多消费组的话，那么这个PEL占用的内存就会放大。

### PEL如何避免消息丢失

在客户端消费者读取Stream消息时，Redis服务器将消息回复给客户端的过程中，客户端突然断开了连接，消息就丢失了。但是PEL里已经保存了发出去的消息ID。待客户端重新连上之后，可以再次收到PEL中的消息ID列表。不过此时xreadgroup的起始消息必须是任意有效的消息ID，一般将参数设为0-0，表示读取所有的PEL消息以及自last_delivered_id之后的新消息。

### 分区Partition

Redis没有原生支持分区的能力，想要使用分区，需要分配多个Stream，然后在客户端使用一定的策略，将消息放入不同的stream。

### 结论

Stream的消费模型借鉴了kafka的消费分组的概念，它弥补了Redis Pub/Sub不能持久化消息的缺陷。但是它又不同于kafka，kafka的消息可以分partition，而Stream不行。如果非要分parition的话，得在客户端做，提供不同的Stream名称，对消息进行hash取模来选择往哪个Stream里塞。

参考文章：

https://blog.csdn.net/enmotech/article/details/81230531

http://www.hellokang.net/redis/message-queue-by-redis.html



